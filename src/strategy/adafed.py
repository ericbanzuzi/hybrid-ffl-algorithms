import json
import os
from logging import INFO, WARNING
from typing import List, Optional, Union

import numpy as np
import torch
from flwr.common import (
    ArrayRecord,
    EvaluateRes,
    FitIns,
    FitRes,
    NDArrays,
    Parameters,
    Scalar,
    logger,
    ndarrays_to_parameters,
    parameters_to_ndarrays,
)
from flwr.server.client_manager import ClientManager
from flwr.server.client_proxy import ClientProxy
from flwr.server.strategy import FedAvg

import wandb


class AdaFedStrategy(FedAvg):
    """Custom AdaFed strategy computing pseudo-gradients.

    Implementation based on "AdaFed: Fair Federated Learning via Adaptive Common Descent Direction"
    from https://arxiv.org/abs/2401.04993.
    """

    def __init__(
        self,
        model_type: str = "cnn",
        dataset: str = "femnist",
        seed: int = 42,
        cli_strategy: str = "fedavg",
        gamma: float = 1.0,
        lr: float = 0.1,
        use_yogi: bool = False,
        use_adam: bool = False,
        beta1: float = 0.9,
        beta2: float = 0.99,
        m_t: Optional[np.ndarray] = None,
        v_t: Optional[np.ndarray] = None,
        tau: float = 1e-10,  # Small constant for stability
        proximal_mu: float = 0.0,
        *args,
        **kwargs,
    ):
        super().__init__(*args, **kwargs)
        self.gamma = gamma
        self.global_weights: Optional[List[np.ndarray]] = None
        self.lr = lr
        self.use_yogi = use_yogi
        self.use_adam = use_adam
        self.beta1 = beta1
        self.beta2 = beta2
        self.m_t = m_t  # type: ignore
        self.v_t = v_t  # type: ignore
        self.tau = tau
        self.t = 0  # Time step for adaptive optimizers
        self.cli_strategy = cli_strategy
        self.proximal_mu = proximal_mu
        self.pre_weights: Optional[Parameters] = None

        # A dictionary that will store the metrics generated on each round
        self.results_to_save = {}

        # Log those same metrics to W&B
        project = f"adafed-{cli_strategy}-{dataset}-{model_type}"
        wandb.init(project=project, name=f"adafed-{cli_strategy}-seed-{seed}")
        self.model_type = model_type
        self.dataset = dataset
        self.best_acc_so_far = 0.0  # Track best accuracy to save model checkpoints
        self.seed = seed

        self.results_dir = f"./experiment-results/{dataset}-{model_type}/"
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)

        self.checkpoint_dir = f"./checkpoints/{dataset}-{model_type}/"
        if not os.path.exists(self.checkpoint_dir):
            os.makedirs(self.checkpoint_dir)

    def __repr__(self) -> str:
        """Compute a string representation of the strategy."""
        rep = f"AdaFed(accept_failures={self.accept_failures})"
        return rep

    def configure_fit(
        self, server_round: int, parameters: Parameters, client_manager: ClientManager
    ) -> list[tuple[ClientProxy, FitIns]]:
        """Configure the next round of training."""
        weights = parameters_to_ndarrays(parameters)
        self.pre_weights = weights
        parameters = ndarrays_to_parameters(weights)
        config = {}
        if self.on_fit_config_fn is not None:
            # Custom fit config function provided
            config = self.on_fit_config_fn(server_round)
        fit_ins = FitIns(parameters, config)

        # Sample clients
        sample_size, min_num_clients = self.num_fit_clients(
            client_manager.num_available()
        )
        clients = client_manager.sample(
            num_clients=sample_size, min_num_clients=min_num_clients
        )

        # Return client/config pairs
        return [(client, fit_ins) for client in clients]

    def _update_best_acc(
        self, current_round: int, accuracy: float, arrays: ArrayRecord
    ) -> None:
        """Update best accuracy and save model checkpoint if current accuracy is higher."""
        if accuracy > self.best_acc_so_far:
            self.best_acc_so_far = accuracy
            logger.log(INFO, "üí° New best global model found: %f", accuracy)
            # Save the PyTorch model
            file_name = (
                f"adafed-{self.cli_strategy}-round-{current_round}-seed-{self.seed}.pt"
            )
            torch.save(
                arrays.to_torch_state_dict(), f"{self.checkpoint_dir}/{file_name}"
            )
            logger.log(INFO, "üíæ New best model saved to disk: %s", file_name)

    def aggregate_fit(
        self,
        server_round: int,
        results: list[tuple[ClientProxy, FitRes]],
        failures: list[Union[tuple[ClientProxy, FitRes], BaseException]],
    ) -> tuple[Optional[Parameters], dict[str, Scalar]]:
        """Aggregate fit results using weighted average."""
        if not results:
            return None, {}
        # Do not aggregate if there are failures and failures are not accepted
        if not self.accept_failures and failures:
            return None, {}

        if self.pre_weights is None:
            raise AttributeError("AdaFed pre_weights are None in aggregate_fit")

        initial_parameters = self.pre_weights
        grads, losses = [], []
        for _, fit_res in results:
            # Compute pseudo-gradient as single d-dimensional vectors
            new_parameters = parameters_to_ndarrays(fit_res.parameters)
            pseudo_gradient: NDArrays = np.concatenate(
                [x - y for x, y in zip(initial_parameters, new_parameters)],
                axis=None,
            )

            grads.append(pseudo_gradient)
            losses.append(fit_res.metrics["train-loss"])

            if fit_res.metrics["train-loss"] <= 0:
                logger.log(
                    WARNING,
                    "Client reported non-positive train-loss, which may lead to instability in AdaFed.",
                )

        # Orthogonalize gradients
        orthograds = self.modified_gram_schmidt(np.stack(grads), losses, self.gamma)

        # Minimum norm element
        d_t = self.compute_convex_combination(orthograds)
        logger.log(INFO, f"üö• Computed d_t with norm {np.linalg.norm(d_t)}")

        if self.use_yogi or self.use_adam:
            d_t = self.compute_adjusted_dt(d_t)

        # Update current weights
        adafed_result = self.update_model_with_direction(d_t, initial_parameters)
        self.pre_weights = adafed_result
        parameters_aggregated = ndarrays_to_parameters(adafed_result)

        # Aggregate custom metrics if aggregation fn was provided
        metrics_aggregated = {}
        if self.fit_metrics_aggregation_fn:
            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]
            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)
        elif server_round == 1:  # Only log this warning once
            logger.log(WARNING, "No fit_metrics_aggregation_fn provided")

        # Store metrics as dictionary
        my_results = metrics_aggregated
        self.results_to_save[server_round] = my_results

        # Save metrics as json
        with open(
            f"{self.results_dir}/adafed-{self.cli_strategy}-results-seed-{self.seed}.json",
            "w",
        ) as json_file:
            json.dump(self.results_to_save, json_file, indent=4)

        # Log metrics to W&B
        wandb.log(my_results, step=server_round)

        # Save new Global Model as a PyTorch checkpoint
        self._update_best_acc(
            current_round=server_round,
            accuracy=metrics_aggregated.get("avg-val-accuracy", 0.0),
            arrays=ArrayRecord.from_numpy_ndarrays(adafed_result),
        )

        logger.log(INFO, f"‚úÖ Completed aggregation for round {server_round}")
        logger.log(
            INFO,
            f"Avg-train-accuracy: {metrics_aggregated.get('avg-val-accuracy', 0.0)} | Avg-train-loss: {metrics_aggregated.get('avg-train-loss', 0.0)}",
        )

        # Return the expected outputs for `fit`
        return parameters_aggregated, metrics_aggregated

    def loss_avg(
        self,
        losses: list[float],
    ) -> tuple[float, float]:
        """Compute weighted average loss."""
        if not losses:
            return 0.0, 0.0
        return np.mean(losses), np.std(losses, ddof=0)

    def aggregate_evaluate(
        self,
        server_round: int,
        results: list[tuple[ClientProxy, EvaluateRes]],
        failures: list[Union[tuple[ClientProxy, EvaluateRes], BaseException]],
    ) -> tuple[Optional[float], dict[str, Scalar]]:
        """Aggregate evaluation losses using weighted average."""
        # Modified from FedAvg.aggregate_evaluate to save metrics and log to W&B
        if not results:
            return None, {}
        # Do not aggregate if there are failures and failures are not accepted
        if not self.accept_failures and failures:
            return None, {}

        # Aggregate loss
        loss_aggregated, std_loss_aggregated = self.loss_avg(
            [evaluate_res.loss for _, evaluate_res in results]
        )

        # Aggregate custom metrics if aggregation fn was provided
        metrics_aggregated = {}
        if self.evaluate_metrics_aggregation_fn:
            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]
            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)
        elif server_round == 1:  # Only log this warning once
            logger.log(WARNING, "No evaluate_metrics_aggregation_fn provided")

        # Store metrics as dictionary
        my_results = {
            "avg-test-loss": loss_aggregated,
            "std-test-loss": std_loss_aggregated,
            **metrics_aggregated,
        }

        # Insert into local dictionary
        self.results_to_save[server_round] = {
            **self.results_to_save[server_round],
            **my_results,
        }

        # Save metrics as json
        with open(
            f"{self.results_dir}/adafed-{self.cli_strategy}-results-seed-{self.seed}.json",
            "w",
        ) as json_file:
            json.dump(self.results_to_save, json_file, indent=4)

        # Log metrics to W&B
        wandb.log(my_results, step=server_round)
        logger.log(INFO, f"‚úÖ Completed evaluation for round {server_round}")
        logger.log(
            INFO,
            f"Avg-test-accuracy: {metrics_aggregated.get('avg-test-accuracy', 0.0)} | Avg-test-loss: {loss_aggregated}",
        )

        # Return the expected outputs for `evaluate`
        return loss_aggregated, metrics_aggregated

    @staticmethod
    # Modified Gram-Schmidt from https://arxiv.org/abs/2401.04993, step 1
    def modified_gram_schmidt(
        gradients: np.ndarray, losses: np.ndarray, gamma: float = 1.0
    ) -> np.ndarray:
        """Modified Gram-Schmidt with numerical stability checks."""
        K, D = gradients.shape
        ortho_grads = np.zeros_like(gradients)
        eps = 1e-10  # Add small epsilon for numerical stability

        # Eq. 5
        ortho_grads[0] = gradients[0] / (np.abs(losses[0]) ** gamma + eps)

        # Eq. 6
        for k in range(1, K):
            gk = gradients[k]
            fk_gamma = np.abs(losses[k]) ** gamma

            proj_sum = np.zeros_like(gk)
            for i in range(k):
                gi_tilde = ortho_grads[i]
                denom = np.dot(gi_tilde, gi_tilde)
                if denom > eps:
                    proj_sum += (np.dot(gk, gi_tilde) / denom) * gi_tilde

            numerator = gk - proj_sum

            # Compute denominator with numerical stability
            denom_correction = sum(
                np.dot(gk, ortho_grads[i])
                / (np.dot(ortho_grads[i], ortho_grads[i]) + eps)
                for i in range(k)
            )
            denominator = fk_gamma - denom_correction

            # Add clipping to prevent explosion
            if np.abs(denominator) < eps:
                # If denominator is near zero, skip normalization (keep unnormalized gradient)
                ortho_grads[k] = numerator / (eps * 10)
                logger.log(
                    WARNING, f"Near-zero denominator at k={k}, using small value"
                )
            else:
                ortho_grads[k] = numerator / denominator

        return ortho_grads

    @staticmethod
    # Convex hull minimum norm from https://arxiv.org/abs/2401.04993, step 2
    def compute_convex_combination(ortho_grads: np.ndarray):
        """Compute minimum norm element in convex hull of orthogonalized gradients."""
        norm_squared = np.linalg.norm(ortho_grads, axis=1) ** 2
        alpha = 2 / np.sum(1.0 / norm_squared)  # Eq. 13
        lambdas = alpha / (2 * norm_squared)  # Eq. 12
        v_t = np.sum(lambdas[:, np.newaxis] * ortho_grads, axis=0)
        return v_t

    def update_model_with_direction(
        self, d_t: np.ndarray, base_weights: List[np.ndarray]
    ):
        # d_t is flat, base_weights is list of arrays with original shapes
        new_weights = []
        offset = 0
        for w in base_weights:
            shape, size = w.shape, np.prod(w.shape)
            delta = d_t[offset : offset + size].reshape(shape)
            new_w = w + self.lr * delta
            new_weights.append(new_w)
            offset += size
        return new_weights

    def compute_adjusted_dt(self, d_t: np.ndarray) -> np.ndarray:
        if self.use_yogi:
            # FedYogi (adaptive learning rate)
            # Initialize moment estimates if not already done
            if self.m_t is None:
                self.m_t = np.zeros_like(d_t)
            if self.v_t is None:
                self.v_t = np.zeros_like(d_t)
                logger.log(INFO, "‚û°Ô∏è Initialized Yogi moments")

            # FedYogi update rule based on "Adaptive Federated Optimization" from https://arxiv.org/pdf/2003.00295v5
            self.t += 1
            self.m_t = self.beta1 * self.m_t + (1 - self.beta1) * d_t
            self.v_t = self.v_t - (1 - self.beta2) * (d_t**2) * np.sign(
                self.v_t - d_t**2
            )
            # self.m_that = self.m_t / (1 - self.beta1 ** self.t)  # Bias correction
            # self.v_that = self.v_t / (1 - self.beta2 ** self.t)  # Bias correction
            self.m_that = self.m_t
            self.v_that = self.v_t
            adjusted_dt = self.m_that / (np.sqrt(self.v_that) + self.tau)

        elif self.use_adam:
            # Adam (adaptive learning rate)
            # Initialize moment estimates if not already done
            if self.m_t is None:
                self.m_t = np.zeros_like(d_t)
            if self.v_t is None:
                self.v_t = np.zeros_like(d_t)
                logger.log(INFO, "‚û°Ô∏è Initialized Adam moments")

            # Adam update rule based on "Adaptive Federated Optimization" from https://arxiv.org/pdf/2003.00295v5
            self.t += 1
            self.m_t = self.beta1 * self.m_t + (1 - self.beta1) * d_t
            self.v_t = self.beta2 * self.v_t + (1 - self.beta2) * (d_t**2)
            # self.m_that = self.m_t / (1 - self.beta1 ** self.t)  # Bias correction
            # self.v_that = self.v_t / (1 - self.beta2 ** self.t)  # Bias correction
            self.m_that = self.m_t
            self.v_that = self.v_t
            adjusted_dt = self.m_that / (np.sqrt(self.v_that) + self.tau)
        else:
            adjusted_dt = d_t

        return adjusted_dt
